# ai_services.py

import json
import re
import time
import streamlit as st
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
from docx import Document # Word Ã‡Ä±ktÄ±sÄ± Ä°Ã§in
from docx.shared import Inches, Pt, RGBColor
from io import BytesIO

# ==========================================
# ğŸ§  AI MODEL SEÃ‡ENEKLERÄ° (GÃœNCEL)
# ==========================================
AVAILABLE_MODELS = {
    "Derin AraÅŸtÄ±rma": "gemini-3-pro-preview", 
    "GeliÅŸmiÅŸ": "gemini-2.5-pro",
    "HÄ±zlÄ±": "gemini-2.5-flash"
}

def clean_bold_tags(text: str) -> str:
    """Markdown **bold**'larÄ± HTML <b> tag'ine Ã§evirir."""
    text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)
    text = re.sub(r'\*(.*?)\*', r'<i>\1</i>', text)
    return text

def _get_model(api_key: str, model_name: str):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(model_name)

# --- WORD ONE-PAGER OLUÅTURUCU ---
def create_one_pager(dna_data, intel_data, cover_image=None):
    """
    Kitap verilerinden ÅŸÄ±k bir Word (.docx) bÃ¼lteni oluÅŸturur.
    """
    doc = Document()
    
    # BaÅŸlÄ±k
    title = doc.add_heading(dna_data.get('kitap_adi', 'Kitap TanÄ±tÄ±mÄ±'), 0)
    title.alignment = 1 # OrtalÄ±
    
    # Alt BaÅŸlÄ±k (Pitch)
    if dna_data.get('pitch'):
        p = doc.add_paragraph()
        run = p.add_run(f"\"{dna_data['pitch']}\"")
        run.italic = True
        run.font.size = Pt(14)
        run.font.color.rgb = RGBColor(255, 140, 0) # Turuncu
        p.alignment = 1

    # Kapak Resmi (Varsa)
    if cover_image:
        try:
            doc.add_picture(cover_image, width=Inches(2.5))
            last_paragraph = doc.paragraphs[-1] 
            last_paragraph.alignment = 1
        except:
            pass

    # KÃ¼nye Tablosu
    table = doc.add_table(rows=1, cols=2)
    hdr_cells = table.rows[0].cells
    hdr_cells[0].text = 'KÃœNYE'
    hdr_cells[1].text = 'DETAYLAR'
    
    row = table.add_row().cells
    row[0].text = f"Yazar: {dna_data.get('yazar', '-')}\nTÃ¼r: {dna_data.get('ana_tur', '-')}\nHedef: {dna_data.get('hedef_kitle', '-')}"
    row[1].text = f"Sayfa: {intel_data.get('sayfa', '-')}\nPuan: {intel_data.get('puan', '-')}\nDil: {dna_data.get('dil_seviyesi', '-')}"

    # Ä°Ã§erik
    doc.add_heading('Ã–zet & Atmosfer', level=1)
    doc.add_paragraph(intel_data.get('yorum_ozeti', 'Ã–zet bilgisi bulunamadÄ±.'))
    
    doc.add_heading('SatÄ±ÅŸ NoktalarÄ± (Selling Points)', level=1)
    doc.add_paragraph(f"â€¢ Tempo: {dna_data.get('tempo', '-')}")
    doc.add_paragraph(f"â€¢ Benzer Eserler: {dna_data.get('benzer_kitaplar', '-')}")
    
    # KayÄ±t
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def analyze_book_dna(full_text: str, api_key: str, model_name: str):
    """
    Kitap DNA'sÄ±nÄ± Ã§Ä±karÄ±r. (Context-Aware + Yeni Metrikler)
    """
    model = _get_model(api_key, model_name)

    # 1. ÅÃœPHELÄ° SÄ°NYAL TARAMASI (REGEX)
    keywords = {
        "lgbt_sinyalleri": [
            r"\bgay\b", r"\blezbiyen", r"\beÅŸcinsel", r"\bqueer", r"\btrans\b",
            r"\bhemcins", r"\biki baba", r"\biki anne", r"\bnon-binary", 
            r"\bkuir", r"\bpartner", r"\bsevgili", r"\bhoÅŸlan", r"\baÅŸÄ±k"
        ],
        "erotizm_cinsellik": [
            r"\bseviÅŸ", r"\byatak", r"\bÃ§Ä±plak", r"\bsoyun", r"\barzu", 
            r"\bÅŸehvet", r"\bÃ¶pÃ¼ÅŸ", r"\bkalÃ§a", r"\bgÃ¶ÄŸÃ¼s", r"\bmemeler", 
            r"\bkasÄ±k", r"\binledi", r"\bsÃ¼rtÃ¼n", r"\bprezervatif", r"\bkorunma",
            r"\bnefes nefese", r"\bten tene"
        ],
        "alkol_uyusturucu": [
            r"\bÅŸarap", r"\bviski", r"\bsigara", r"\balkol", r"\biÃ§ki", r"\bbira", 
            r"\bkokain", r"\besrar", r"\bhap\b", r"\buyuÅŸturucu", r"\biÄŸne", 
            r"\bkriz", r"\bduman", r"\btoz", r"\bmadde", r"\bkristal", r"\bot\b"
        ],
        "siddet_travma": [
            r"\bkan\b", r"\bceset", r"\bcinayet", r"\bintihar", r"\bÃ¶ldÃ¼r", 
            r"\bboÄŸdu", r"\bbÄ±Ã§ak", r"\bsilah", r"\btabanca", r"\btecavÃ¼z", 
            r"\btaciz", r"\bistismar", r"\bdayak", r"\bkesik", r"\bvahÅŸet",
            r"\biÅŸkence", r"\bkemik"
        ],
        "siyasi_dini_hassas": [
            r"\btanrÄ±", r"\bkilise", r"\bcamii", r"\bÃ¶rgÃ¼t", r"\bterÃ¶r", 
            r"\bdarbe", r"\bdevrim", r"\bbaÅŸkaldÄ±rÄ±", r"\bpropaganda", 
            r"\balevi", r"\bkÃ¼rt", r"\bermeni", r"\byahudi", r"\bhristiyan",
            r"\bÃ¼kÃ¼met", r"\basker", r"\bpolis"
        ]
    }
    
    detected = []
    text_lower = full_text.lower()
    for cat, pats in keywords.items():
        for pat in pats:
            if re.search(pat, text_lower):
                clean_word = pat.replace(r'\b', '').replace('\\', '')
                detected.append(f"- {cat.upper()} ÅÃ¼phesi (Kelime: {clean_word})")
                break
                
    clues_str = "\n".join(detected) if detected else "Otomatik tarama temiz."

    # 2. YARGIÃ‡ AI PROMPTU
    prompt = f"""
    GÃ–REV: Sen kÄ±demli bir Adli YayÄ±n EditÃ¶rÃ¼ ve Hassasiyet OkumanÄ±sÄ±n.
    AMACIN: KitabÄ±n DNA'sÄ±nÄ±, risklerini ve ticari potansiyelini analiz etmek.
    
    OTOMATÄ°K SÄ°NYALLER: {clues_str}
    METÄ°N (TAMAMI): {full_text}
    
    Ä°STENEN ANALÄ°ZLER:
    1. LÄ°NGUÄ°STÄ°K: Dil ne kadar aÄŸÄ±r? Ã‡eviri zorluÄŸu ne? (Basit/Orta/AÄŸÄ±r)
    2. TEMPO (PACING): Kitap nasÄ±l akÄ±yor? (Slow Burn / Page-Turner)
    3. X MEETS Y: "Harry Potter ile Sherlock Holmes buluÅŸuyor" gibi bir pitch formÃ¼lÃ¼ Ã¼ret.
    4. RÄ°SKLER: LGBT, Åiddet vb. konularda "BaÄŸlam" (Context) kontrolÃ¼ yap.
    
    Ã‡IKTI FORMATI (JSON):
    {{
       "kitap_adi": "...", "yazar": "...", 
       "hedef_kitle": "...", "ana_tur": "...", "alt_turler": "...",
       "dil_seviyesi": "...", "tempo": "...", "pitch": "...",
       "lgbt": "VAR (KanÄ±t...) / YOK", 
       "cinsellik": "VAR (KanÄ±t...) / YOK", 
       "alkol_madde": "VAR (KanÄ±t...) / YOK",
       "siddet": "VAR (KanÄ±t...) / YOK", 
       "siyasi_dini": "VAR (KanÄ±t...) / YOK",
       "atmosfer": "...", "temalar": "...", "benzer_kitaplar": "..."
    }}
    """
    try:
        response = model.generate_content(
            prompt,
            generation_config=GenerationConfig(response_mime_type="application/json")
        )
        return json.loads(response.text)
    except Exception:
        return None

def run_matchmaker_batch(book_dna: dict, publishers: list, api_key: str, model_name: str):
    """YayÄ±nevi eÅŸleÅŸtirme (JSON Mode + Sert Prompt)."""
    model = _get_model(api_key, model_name)
    batch_size = 5
    all_results = []
    progress_bar = st.progress(0)
    total_pubs = len(publishers)
    
    for i in range(0, total_pubs, batch_size):
        batch = publishers[i:i + batch_size]
        batch_profiles = [p["AI_PROFIL"] for p in batch]
        
        prompt = f"""
        ROLE: Sen acÄ±masÄ±z ama adil bir YayÄ±n EÅŸleÅŸtirme UzmanÄ±sÄ±n.
        GÃ–REV: Kitap DNA'sÄ± ile YayÄ±nevi Profillerini eÅŸleÅŸtir.
        KÄ°TAP DNA'SI: {json.dumps(book_dna, ensure_ascii=False)}
        ADAY YAYINEVLERÄ°: {json.dumps(batch_profiles, ensure_ascii=False)}
        KURALLAR:
        1. YayÄ±nevi adÄ±nÄ± tam kopyala.
        2. Her yayÄ±nevi iÃ§in mutlaka bir sonuÃ§ Ã¼ret.
        3. SEBEP ALANI ASLA BOÅ KALAMAZ. Puan 0 olsa bile nedenini aÃ§Ä±kÃ§a yaz.
        PUANLAMA: 0-30 Uyumsuz, 40-60 Olabilir, 70-100 MÃ¼kemmel.
        Ã‡IKTI FORMATI (JSON ARRAY): [ {{"yayÄ±nevi": "...", "uyum_skoru": 0, "sebep": "..."}} ]
        """
        
        try:
            response = model.generate_content(
                prompt,
                generation_config=GenerationConfig(response_mime_type="application/json")
            )
            raw_results = json.loads(response.text)
            for res in raw_results:
                clean_name = res.get("yayÄ±nevi", "").replace("YAYINEVÄ° ID/ADI:", "").strip()
                res["yayÄ±nevi"] = clean_name
                if not res.get("sebep"): res["sebep"] = "AI sebep belirtmedi."
            all_results.extend(raw_results)
        except Exception as e:
            for pub in batch:
                all_results.append({"yayÄ±nevi": pub["yayÄ±nevi"], "uyum_skoru": 0, "sebep": f"HATA: {str(e)}"})
        
        if total_pubs > 0: progress_bar.progress(min((i + batch_size) / total_pubs, 1.0))
        time.sleep(1)
        
    progress_bar.empty()
    return all_results

def refine_intelligence(raw_text: str, api_key: str):
    """Ä°stihbarat temizleme (Flash Modeli)."""
    model = _get_model(api_key, "gemini-2.5-flash") 
    prompt = f"GÃ–REV: Ä°stihbarat Analisti. Ham veriden Ã¶zet rapor Ã§Ä±kar.\nHAM VERÄ°: {raw_text}\nÄ°STENENLER: Puan, Sayfa SayÄ±sÄ±, Ã–dÃ¼ller, Yazar Biyografisi, Hak SatÄ±ÅŸlarÄ±.\nJSON FormatÄ±nda ver: {{'puan': '...', 'sayfa': '...', 'oduller': '...', 'yazar': '...', 'satislar': '...', 'ozet': '...'}}"
    try:
        response = model.generate_content(prompt, generation_config=GenerationConfig(response_mime_type="application/json"))
        return json.loads(response.text)
    except:
        return {}

def run_drafter(full_text, notes, book_name, intel, book_dna, api_key, model_name):
    """SatÄ±ÅŸ mektubu yazarÄ± (Disiplinli Mod)."""
    model = _get_model(api_key, model_name)

    def clean_val(val):
        if isinstance(val, list): return ", ".join(str(v) for v in val)
        return str(val) if val else "BelirtilmemiÅŸ"

    # Link KontrolÃ¼
    book_name_instruction = book_name
    if str(book_name).strip().startswith("http"):
        book_name_instruction = f"KullanÄ±cÄ± kitap adÄ± yerine link girdi ({book_name}). LÃ¼tfen 'external_intelligence' raporundan kitabÄ±n GERÃ‡EK ADINI bul ve metinlerde onu kullan."

    # Intel Verisini Stringe Ã‡evir (Drafter JSON okuyamazsa diye)
    intel_str = json.dumps(intel, ensure_ascii=False) if isinstance(intel, dict) else str(intel)

    instruction_set = {
        "role_definition": {
            "role": "Foreign Rights Manager ve Pazarlama UzmanÄ±",
            "objective": "YabancÄ± bir kitap iÃ§in TÃ¼rk yayÄ±ncÄ±lara satÄ±ÅŸ odaklÄ± HTML e-posta yazmak."
        },
        "input_data": {
            "book_name_instruction": book_name_instruction,
            "external_intelligence": intel_str, 
            "editor_notes": notes,
            "book_dna": book_dna
        },
        "content_blueprint": {
            "steps": [
                {
                    "part": "1. GiriÅŸ",
                    "content": f"Åu kalÄ±bÄ± kullan: 'BugÃ¼n sizlere [SÄ±fat 1], [SÄ±fat 2] ve [SÄ±fat 3] bir {book_dna.get('ana_tur', 'kitap')} eserle gelmek istiyorum.' KRÄ°TÄ°K: EÅŸ anlamlÄ± sÄ±fat yasak. Merhaba/NasÄ±lsÄ±n yasak."
                },
                { "part": "2. Hook", "content": "KitabÄ± tek cÃ¼mlede satan vurucu kanca." },
                {
                    "part": "3. KÃ¼nye",
                    "content": "HTML Listesi (<ul>). Kitap AdÄ±, Yazar, YayÄ±n Tarihi, Sayfa SayÄ±sÄ± (Intel verisinden al, yoksa 'BelirtilmemiÅŸ' yaz), TÃ¼r, Temalar."
                },
                { "part": "4. Ã–zet", "content": "Olay Ã¶rgÃ¼sÃ¼ ve duygu (1-2 paragraf)." },
                { "part": "5. Yazar", "content": "'Yazar HakkÄ±nda:' baÅŸlÄ±ÄŸÄ±. Sadece kanÄ±tlanabilir gerÃ§ekler (doÄŸum, eÄŸitim, Ã¶dÃ¼l). Yoksa 'Bilgi yok' de." },
                { "part": "6. BaÅŸarÄ±lar", "content": "Intel verisinden Ã–dÃ¼ller, Listeler, Puan ve Hak SatÄ±ÅŸlarÄ±nÄ± listele. Veri yoksa bu bÃ¶lÃ¼mÃ¼ sil." },
                { "part": "7. KapanÄ±ÅŸ", "content": "Ticari potansiyel vurgusu (Dizi/Film yok). 'CevabÄ±nÄ±zÄ± bekler, keyifli okumalar dilerim.'" }
            ]
        },
        "strict_formatting_rules": {
            "output_format": "PURE HTML",
            "forbidden": ["Markdown", "Code Blocks", "Greeting Sentences"],
            "required_syntax": {"spacing": "Use <br> for breaks."}
        }
    }

    prompt_json = json.dumps(instruction_set, ensure_ascii=False, indent=2)
    final_prompt = f"AÅŸaÄŸÄ±daki JSON talimat setini uygula. Ã‡Ä±ktÄ± sadece HTML olmalÄ±.\nTALÄ°MAT SETÄ°:\n{prompt_json}"

    try:
        response = model.generate_content(final_prompt)
        text = response.text or ""
        text = text.replace("```html", "").replace("```json", "").replace("```", "").strip()
        text = clean_bold_tags(text)
        text = re.sub(r'<\s*br\s*/?>', '<br>', text, flags=re.IGNORECASE)
        text = re.sub(r'(<br>\s*)+', '<br>', text)
        return text
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"